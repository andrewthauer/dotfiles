#!/usr/bin/env bash
# Summary:
#   Wrapper for various kafka commands
#
# Usage:
#   kafka [command]
#
# Options:
#   -b | --broker           The seed broker (default: localhost:9092)
#   -r | --registry-url     The schema registry url (default: http://localhost:8081)
#   -c | --connect-url      The kafka connect url (default: http://localhost:8083)
#   -k | --with-key         Use a key seperator when producing messages
#   -K | --key-seperator    The key seperator (default ':')
#
# Examples:
#   kafka help
#   kafka topic-list
#   kafka topic-create some-topic

usage() {
  echo "Usage: kafka [command]"
  echo ""
  echo "COMMANDS:"
  echo "  help                Prints this message"
  list_commands | sed "s/^/  /"
}

#
# Broker
#

# Usage: kafka shell [CONTAINER_NAME]
#   CONTAINER_NAME    The container name (broker | schema-registry | connect)
kafka-shell() {
  docker_exec_cmd "${1:-broker}" "${2:-bash}"
}

# Usage: kafka topic-list
kafka-topic-list() {
  broker_cmd kafka-topics --bootstrap-server "${BROKER}" --list "${@}"
}

# Usage: kafka topic-create [TOPIC]
#   TOPIC     The topic name
kafka-topic-create() {
  broker_cmd kafka-topics --bootstrap-server "${BROKER}" --create --topic "${1}" "${@:2}"
}

# Usage: kafka topic-describe [TOPIC]
#   TOPIC     The topic name to create
kafka-topic-describe() {
  broker_cmd kafka-topics --bootstrap-server "${BROKER}" --describe --topic "${1}" "${@:2}"
}

# Usage: kafka topic-delete [TOPIC]
#   TOPIC     The topic name to delete
kafka-topic-delete() {
  broker_cmd kafka-topics --bootstrap-server "${BROKER}" --delete --topic "${1}" "${@:2}"
}

# Usage: kafka produce [TOPIC]
#   TOPIC     The topic name produce messages to
kafka-produce() {
  [ -n "$WITH_KEY" ] && with_keys_options="--property parse.key=true --property key.separator=${KEY_SEPERATOR}"

  # shellcheck disable=SC2086
  broker_cmd kafka-console-producer --bootstrap-server "${BROKER}" \
    $with_keys_options \
    --topic "${1}" \
    "${@:2}"

  # kafkacat -P -b "${BROKER}" -t "${1}" "${@:2}"
}

# Usage:  kafka consume [TOPIC]
#   TOPIC     The topic name consume messages from
kafka-consume() {
  [ -n "$WITH_KEY" ] && with_keys_options="--property print.key=true"

  # shellcheck disable=SC2086
  broker_cmd kafka-console-consumer --bootstrap-server "${BROKER}" \
    $with_keys_options \
    --topic "${1}" \
    --from-beginning \
    "${@:2}"

  # kafkacat -C -b "${BROKER}" -t "${1}" "${@:2}"
}

# Usage: kafka produce-avro [TOPIC]
#   TOPIC     The topic to produce messages to
kafka-produce-avro() {
  local bootstrap_server="${SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS:-broker:29092}"

  # shellcheck disable=SC2089
  local with_keys_options
  # shellcheck disable=SC2286
  [ -n "$WITH_KEY" ] && with_keys_options="--property parse.key=true --property key.separator=" ""

  # shellcheck disable=SC2086
  schema_registry_cmd kafka-avro-console-producer \
    --bootstrap-server "${bootstrap_server}" \
    $with_keys_options \
    --topic "${1}" \
    --property schema.registry.url="${SCHEMA_REGISTRY_URL}" \
    --property value.schema.id="$(kafka-schema-version "${1}-value" | jq -r '.id')" \
    "${@:2}"
}

# Usage: kafka consume-avro [TOPIC]
#   TOPIC     The topic to consume messages from
kafka-consume-avro() {
  local bootstrap_server="${SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS:-broker:29092}"
  local with_keys_options
  [ -n "$WITH_KEY" ] && with_keys_options="--property print.key=true"

  # shellcheck disable=SC2086
  schema_registry_cmd kafka-avro-console-consumer \
    --bootstrap-server "${bootstrap_server}" \
    $with_keys_options \
    --topic "${1}" \
    --property schema.registry.url="${SCHEMA_REGISTRY_URL}" \
    --from-beginning \
    "${@:1}"

  # kafkacat -C -b "${BROKER}" -s avro -r "${SCHEMA_REGISTRY_URL}" -t "${1}" "${@:2}"
}

#
# Schema Registry
#

# Usage: kafka schema-api [VERB] [PATH] [DATA]
kafka-schema-api() {
  schema_registry_curl "${@}"
}

# Usage: kafka schema-add [AVCS_PATH] [TYPE=key|value]
#   AVCS_PATH       The path to the avro .avcs file
#   TYPE            Optional subject type - key | value (default)
kafka-schema-add() {
  local path
  path="$(basename "$1")"
  local subject="${path%%.*}"
  local type="${2-value}"
  local schema
  schema="$(cat <"${1:-/dev/stdin}" | jq '.')"

  local data
  data="$(jq -r -n --argjson schema "$schema" '{schema: $schema | tostring}')"
  schema_registry_curl POST "/subjects/${subject}-${type}/versions" "$data"
}

# Usage: kafka schema-config [COMPATIBILITY]
#   COMPATIBILITY     The compatability mode to set (if provided)
kafka-schema-config() {
  local compatibility="${1}" # BACKWARD | NONE

  if [ -z "${compatibility}" ]; then
    schema_registry_curl GET "/config"
  else
    local data
    data="$(jq -r -n --arg compat "$compatibility" '{compatibility: $compat | tostring}')"
    schema_registry_curl PUT "/config" "$data"
  fi
}

# Usage: kafka schema-get [SUBJECT] [VERSION]
#   SUBJECT   The schema subject name
kafka-schema-get() {
  local subject="${1}"
  local version="${2:-latest}"
  schema_registry_curl GET "/subjects/${subject}/versions/${version}/schema"
}

# Usage: kafka schema-list
kafka-schema-list() {
  schema_registry_curl GET "/subjects"
}

# Usage: kafka schema-deleta [SUBJECT]
#   SUBJECT   The schema subject name to use (latest version used)
kafka-schema-delete() {
  local subject="${1}"
  schema_registry_curl DELETE "/subjects/${subject}"
}

# Usage: kafka schema-version [SUBJECT] [VERSION]
#   SUBJECT   The schema subject name
#   VERSION   The schema version
kafka-schema-version() {
  local subject="${1}"
  local version="${2:-latest}"
  schema_registry_curl GET "/subjects/${subject}/versions/${version}"
}

# Usage: kafka schema-version-list [SUBJECT]
#   SUBJECT   The schema subject name
kafka-schema-version-list() {
  local subject="${1}"
  schema_registry_curl GET "/subjects/${subject}/versions"
}

# Usage: kafka schema-encode [SUBJECT]
#   SUBJECT   The schema subject name
kafka-schema-encode() {
  avro-tools fromjson --schema "$(kafka-schema-get "${1}")" - 2>/dev/null
}

#
# Avro
#

# Usage: stdout | kafka avro-encode [SCHEMA_PATH]
#   SCHEMA_PATH   The path to the avro schema
kafka-avro-encode() {
  avro-tools fromjson --schema "$(cat "${1}")" - 2>/dev/null
}

# Usage: stdout | kafka avro-decode [SCHEMA_PATH]
#   SCHEMA_PATH   The path to the avro schema
kafka-avro-decode() {
  avro-tools tojson --reader-schema "$(cat "${1}")" - 2>/dev/null
}

#
# Kafak Connect
#

# Usage: kafka connect-api [VERB] [PATH] [DATA]
kafka-connect-api() {
  connect_curl "${@}"
}

# Usage: kafka connector [CONNECTOR]
#   CONNECTOR   The name of the connector
kafka-connector() {
  connect_curl GET "/connectors/${1}"
}

# Usage: kafka connector-add [PATH]
#   PATH    The path to the connector json
kafka-connector-add() {
  local data
  data="$(cat <"${1:-/dev/stdin}" | jq '.')"
  connect_curl POST "/connectors" "$data"
}

# Usage: kafka connector-update [PATH]
#   PATH    The path to the connector json
kafka-connector-update() {
  local data
  data="$(cat <"${1:-/dev/stdin}" | jq -r '.config')"
  connect_curl PUT "/connectors/$(get_connector_name "${1}")/config" "$data"
}

# Usage: kafka connector-validate [PATH]
#   PATH    The path to the connector json
kafka-connector-validate() {
  local data
  data="$(cat <"${1:-/dev/stdin}" | jq -r '.config')"
  connect_curl PUT "/connector-plugins/$(get_connector_class "${1}")/config/validate" "$data"
}

# Usage: kafka connector-status [CONNECTOR]
#   CONNECTOR    The path to the connector json
kafka-connector-status() {
  connect_curl GET "/connectors/${1}/status"
}

# Usage: kafka connector-op [CONNECTOR]
#   CONNECTOR   The name of the connector
kafka-connector-restart() {
  connect_curl POST "/connectors/${1}/restart"
}

# Usage: kafka connector-pause [CONNECTOR]
#   CONNECTOR   The name of the connector
kafka-connector-pause() {
  connect_curl PUT "/connectors/${1}/pause"
}

# Usage: kafka connector-resume [CONNECTOR]
#   CONNECTOR   The name of the connector
kafka-connector-resume() {
  connect_curl PUT "/connectors/${1}/resume"
}

# Usage: kafka connector-delete [CONNECTOR]
#   CONNECTOR   The name of the connector
kafka-connector-delete() {
  connect_curl DELETE "/connectors/${1}"
}

# Usage: kafka connector-tasks [CONNECTOR]
#   CONNECTOR   The name of the connector
kafka-connector-tasks() {
  connect_curl GET "/connectors/${1}/tasks"
}

# Usage: kafka connector-list
kafka-connector-list() {
  connect_curl GET "/connectors"
}

# Usage: kafka connector-plugin-list
kafka-connector-plugin-list() {
  connect_curl GET "/connector-plugins"
}

# Usage: kafka connect-plugin-install [CONNECTOR]
#   CONNECTOR    The connector class name
kafka-connect-plugin-install() {
  connect_cmd confluent-hub install --no-prompt "${1}"
}

get_connector_name() {
  cat <"${1:-/dev/stdin}" | jq -r '.name'
}

get_connector_class() {
  cat <"${1:-/dev/stdin}" | jq -r '.config."connector.class"'
}

#
# Internal functions
#

broker_cmd() {
  docker_exec_cmd "${BROKER_CONTAINER}" "${@}"
}

schema_registry_cmd() {
  docker_exec_cmd "${SCHEMA_REGISTRY_CONTAINER}" "${@}"
}

connect_cmd() {
  docker_exec_cmd "${CONNECT_CONTAINER}" "${@}"
}

docker_exec_cmd() {
  docker exec -it "${1}" "${@:2}"
}

schema_registry_curl() {
  curl_cmd "Content-Type: application/vnd.schemaregistry.v1+json" "${SCHEMA_REGISTRY_URL}" "$@"
}

connect_curl() {
  curl_cmd "Content-Type: application/json" "http://localhost:8083" "$@"
}

curl_cmd() {
  local header="${1}"
  local base_url="${2}"
  local verb="${3}"
  local path="${4}"
  local data="${5}"

  if [ -z "${data}" ]; then
    curl -sS -X "$verb" "${base_url}${path}"
  else
    curl -sS -X "$verb" -H "${header}" --data "${data}" "${base_url}${path}"
  fi
}

function_exists() {
  [ "$(type -t "$1")" == 'function' ]
}

join_by() {
  IFS="$1"
  shift
  echo "$*"
}

list_commands() {
  IFS=$'\n'
  for f in $(declare -F); do
    cmd_name="${f:11}"
    if [[ "${cmd_name}" = kafka-* ]]; then
      echo "${cmd_name}" | cut -c 7-
    fi
  done | sort
}

main() {
  while (("$#")); do
    case "$1" in
      -b | --broker)
        BROKER=$2
        shift 2
        ;;
      -r | --registry-url)
        SCHEMA_REGISTRY_URL=$2
        shift 2
        ;;
      -c | --connect-url)
        CONNECT_URL=$2
        shift 2
        ;;
      -k | --with-key)
        WITH_KEY=true
        shift 1
        ;;
      -K | --key-seperator)
        KEY_SEPERATOR=$2
        shift 2
        ;;
      --) # end argument parsing
        shift
        break
        ;;
      *) # preserve positional arguments
        pos_args="$pos_args $1"
        shift
        ;;
    esac
  done

  # Set positional arguments in their proper place
  eval set -- "$pos_args"

  # Defaults
  BROKER="${BROKER:-localhost:9092}"
  SCHEMA_REGISTRY_URL="${SCHEMA_REGISTRY_URL:-http://localhost:8081}"
  CONNECT_URL="${CONNECT_URL:-http://localhost:8083}"
  KEY_SEPERATOR="${KEY_SEPERATOR:-:}"

  # Docker containers / images
  CONFLUENT_VERSION="${CONFLUENT_VERSION:-6.0.0}"
  BROKER_CONTAINER="${BROKER_CONTAINER:-broker}"
  SCHEMA_REGISTRY_CONTAINER="${SCHEMA_REGISTRY_CONTAINER:-schema-registry}"
  CONNECT_CONTAINER="${CONNECT_CONTAINER:-connect}"

  # parse args
  local cmd="${1:-}"
  local args=("${@:2}")
  local sub_cmd="kafka-${cmd}"

  # Execute the command
  if function_exists "$sub_cmd"; then
    $sub_cmd "${args[@]}" 2>&1
  else
    usage
  fi
}

main "$@"
